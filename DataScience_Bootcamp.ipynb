{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOOO0EhNer2AvkzPXVD9J7+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ZU1310/DataScience-Bootcamp/blob/main/DataScience_Bootcamp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Overview"
      ],
      "metadata": {
        "id": "-K65XDboYOEo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this Session you will be learning about Data Preprocessing and Exploratory Data Analysis(EDA)\n",
        "\n",
        "If you have any doubts regarding any code, please feel free to ask at the end of the session.\n",
        "\n",
        "The resources will be getting shared over the github and Will be uploaded by tommorow Morning. If anyone is unable to access, Kindly connect with over the WhatsApp.\n",
        "\n",
        "The Code will be uploaded on git hub and you will be able to download the code and the dataset to perform from your end."
      ],
      "metadata": {
        "id": "7VlHhndVNJde"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import"
      ],
      "metadata": {
        "id": "fPmnP3YBYSmo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pandas numpy matplotlib seaborn datetime"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5fVGJw6Cs051",
        "outputId": "479246fe-bf0c-4965-8b49-d07919e22ae6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.8.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (0.13.2)\n",
            "Collecting datetime\n",
            "  Downloading DateTime-5.5-py3-none-any.whl.metadata (33 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.0)\n",
            "Collecting zope.interface (from datetime)\n",
            "  Downloading zope.interface-7.1.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.1/44.1 kB\u001b[0m \u001b[31m893.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from zope.interface->datetime) (75.1.0)\n",
            "Downloading DateTime-5.5-py3-none-any.whl (52 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.6/52.6 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading zope.interface-7.1.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (254 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m254.2/254.2 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Import all the necessary libraries and dataset required for the Analysis"
      ],
      "metadata": {
        "id": "sHNatoLGaVs4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import datetime as dt\n",
        "from datetime import datetime, timedelta"
      ],
      "metadata": {
        "id": "UHIYGBkLci-a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('sales_data.csv')"
      ],
      "metadata": {
        "id": "Sshcbf3Kcso9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#df = pd.read_excel('sales_data.xlsx')"
      ],
      "metadata": {
        "id": "KUhXiWnawBYm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pre-Processing"
      ],
      "metadata": {
        "id": "JNZXQE5eYhKe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Here, the data is cleaned and transformed to ensure it's ready for analysis and modeling"
      ],
      "metadata": {
        "id": "tof38YfnahPU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Previewing the Top rows of the DataFrame"
      ],
      "metadata": {
        "id": "Guued_IPdBNk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "1-rNdSAqc3Mj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Previewing the Bottom rows of the DataFrame"
      ],
      "metadata": {
        "id": "qRPRUoYMdzNp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.tail()"
      ],
      "metadata": {
        "id": "ABC9iXYVd2tZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dimensionality of the DataSet"
      ],
      "metadata": {
        "id": "1SO3d5dFd8oo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**When we say Data Feature then we are talking about the columns and\n",
        "when we are saying about the data points then we are talking about the rows**"
      ],
      "metadata": {
        "id": "LggHq6sYyd0b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "VNog-tFfd5Rn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Columns names"
      ],
      "metadata": {
        "id": "1ahs8rj1eC0c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "k_9G2BYVeLzn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Datatypes of Columns"
      ],
      "metadata": {
        "id": "8ppyZU0feR20"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "txOyv0FieabB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Changing the datatype"
      ],
      "metadata": {
        "id": "_IMp0HV5yKyA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['Timestamp'] = df['Timestamp'].astype('datetime64[ns]')"
      ],
      "metadata": {
        "id": "xgKY98Qq8LRm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Convert date into date time format\n"
      ],
      "metadata": {
        "id": "oKmR7emgM1UK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['Date'] = pd.to_datetime(df['Date'])\n"
      ],
      "metadata": {
        "id": "3urrBnUi2Jgq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Timestamp'] = pd.to_datetime(df['Timestamp']).dt.time\n"
      ],
      "metadata": {
        "id": "s7Ws-PQh2Vbt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Checking the Null values"
      ],
      "metadata": {
        "id": "fLJl9fume8eH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "qX_CgwA6fB_g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "vDTI4krf2O98"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Remove Null Value"
      ],
      "metadata": {
        "id": "EKMpCOVffJR6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.dropna(inplace=True)"
      ],
      "metadata": {
        "id": "rbQmjX5W27bi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Duplicate Values"
      ],
      "metadata": {
        "id": "XHXrVGb7fcXt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.duplicated().sum()"
      ],
      "metadata": {
        "id": "CzK-DyfAfgzF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Drop Duplicate"
      ],
      "metadata": {
        "id": "zmemRa0EfkHa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop_duplicates(inplace=True)"
      ],
      "metadata": {
        "id": "gS8iFIGw9nu8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tasks 1 to run this code and show the output whatever you are getting"
      ],
      "metadata": {
        "id": "AQma7a0X5obF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"column_name\"].fillna(\"Fill the Value\", inplace = True)"
      ],
      "metadata": {
        "id": "vbPJuWOmzjyW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Imputing the missing values using Mode function"
      ],
      "metadata": {
        "id": "--Pir5G5_aMW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#df['column_name']= df['column_name'].replace(np.nan, mode)"
      ],
      "metadata": {
        "id": "zuYtnCatzYKp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating a new column from the exisiting column"
      ],
      "metadata": {
        "id": "pDmFKVoBM5kl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['Month'] = df['Date'].dt.month"
      ],
      "metadata": {
        "id": "i3E6qn1o8ByE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature Engineering: This can be part of both Data Preprocessing or EDA\n",
        "Here we will be creating new features which is nothing but your columns in your dataset.\n",
        "This helps to improve the performace of machine learning models"
      ],
      "metadata": {
        "id": "P3JF9IYHfWA8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# df['new_column'] =  df['column1'].apply(lambda x: x * 2)"
      ],
      "metadata": {
        "id": "g8Y2dRRSw9Yu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EDA"
      ],
      "metadata": {
        "id": "XkfgBcJcYjza"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### The Goal is to explore the dataset, identify trends, outliers, and relationships between variables."
      ],
      "metadata": {
        "id": "wrus0yB0a5sT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Descriptive Statistics"
      ],
      "metadata": {
        "id": "VoFAcaYay2P2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "id": "OGjHvWWqy1yd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Distribution of Column"
      ],
      "metadata": {
        "id": "pktJmKe01XSm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "column_distribution = df['Revenue'].value_counts(normalize=True)*100\n",
        "column_distribution"
      ],
      "metadata": {
        "id": "57DCAJLx1QS3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Encoding Catergorical Variable into Numerical"
      ],
      "metadata": {
        "id": "cb64ZSX92Gsv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**One Hot Encoding** is a method of converting categorical variables into a format that can be provided to machine learning algorithms to improve prediction. It involves creating new binary columns for each unique category in a feature. Each column represents one unique category, and a value of 1 or 0 indicates the presence or absence of that category."
      ],
      "metadata": {
        "id": "rApHIw1j3cGN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using Pandas"
      ],
      "metadata": {
        "id": "ey0YE1GV9TrX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#df_encoded = pd.get_dummies(df, dtype=int)\n"
      ],
      "metadata": {
        "id": "2wHmc-v72F7s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using Sklearn One Hot Encoding"
      ],
      "metadata": {
        "id": "KLX7alv59VcP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#from sklearn.preprocessing import OneHotEncoder\n",
        "#onehotencoder = OneHotEncoder()\n",
        "#X = onehotencoder.fit_transform(df.Country.values.reshape(-1, 1)).toarray()\n",
        "#dfOneHot = pd.DataFrame(X, columns=[\"Country_\" + str(int(i)) for i in range(X.shape[1])])\n",
        "#df = pd.concat([df, dfOneHot], axis=1)\n",
        "#df = df.drop(['Country'], axis=1)\n",
        "#df"
      ],
      "metadata": {
        "id": "lkdU2Jb69e_N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using Sklearn Label Encoder"
      ],
      "metadata": {
        "id": "olPjh6F8-gvn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import label encoder\n",
        "#from sklearn import preprocessing\n",
        "\n",
        "# Create a label encoder object\n",
        "#label_encoder = preprocessing.LabelEncoder()\n",
        "\n",
        "# Encode labels in the 'Country' column\n",
        "#df['Country'] = label_encoder.fit_transform(df['Country'])\n",
        "#print(df.head())"
      ],
      "metadata": {
        "id": "ed4XnDwc-fjd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualisation"
      ],
      "metadata": {
        "id": "CZlo_A5Q_kwA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#plt.figure(figsize=(12, 7))\n",
        "#sns.heatmap(data.drop(['Drop_column','ColName'],axis=1).corr(), annot = True, vmin = -1, vmax = 1)\n",
        "#plt.show()"
      ],
      "metadata": {
        "id": "wiQyLvmCAJPi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#plt.figure(figsize=(12, 7))\n",
        "#sns.histplot(data['column_name'])\n",
        "#plt.show()"
      ],
      "metadata": {
        "id": "Xh8m69wGAZ4-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#plt.figure(figsize=(12, 7))\n",
        "#sns.countplot(data['column_name'])\n",
        "#plt.show()"
      ],
      "metadata": {
        "id": "H53I11pjCZqr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modeling"
      ],
      "metadata": {
        "id": "EFgPQbs9YrJh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### This section involves selecting, training and evaluating machine learning models based on the processed data"
      ],
      "metadata": {
        "id": "x9LQwvkbbLej"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusion"
      ],
      "metadata": {
        "id": "b0cIOMNFYsu4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### A summary of the findings, key insights and any recommendations based on the analysis"
      ],
      "metadata": {
        "id": "C1i8-srWb8FV"
      }
    }
  ]
}